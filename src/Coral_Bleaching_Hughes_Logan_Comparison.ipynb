{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Coral Bleaching estimates\n",
    "## Contents\n",
    "1. <a href=\"#intro\">Introduction</a>\n",
    "1. <a href=\"#methods\">Methods</a>\n",
    "1. <a href=\"#data\">Data Sources</a>\n",
    "1. <a href=\"#results\">Results</a>\n",
    "    + Data input and display of raw data\n",
    "        + <a href=\"#HughesData\">Hughes</a>\n",
    "        + <a href=\"#LoganData\">Logan</a>\n",
    "        + <a href=\"#mapcompare\">Map-based comparison of the datasets</a>\n",
    "        + <a href=\"#matching\">Matching of Hughes reef areas to Logan reef cells</a>\n",
    "    + <a href=\"#reefbyreef\">Scatterplot comparisons of Hughes and Logan reef-by-reef data</a>\n",
    "    + <a href=\"#pca\">Principal component analysis to look for variables by which to group reefs</a>\n",
    "    + <a href=\"#variable_scatter\">Scatterplot comparisons of pertinent variables</a>\n",
    "    + <a href=\"#cumulative\">Comparison of world and regional bleaching totals over time</a>\n",
    "1. <a href=\"#refs\">References</a>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction\n",
    "\n",
    "Coral reefs are under anthropogenic stress almost everywhere, and that stress continues to increase.  The most prominent effect is coral bleaching, driven by increases in SST (Freiler 2013).  Understanding this complex phenomenon requires a wide range of science, including ocean circulation and climate modeling, field observations of bleaching, modeling of reef ecosytems, and laboratory work on the biology and biochemistry of corals and their symbiontic dinoflagellates.  This project addresses one small part of the question, attempting to use one set of observational data to validate a global numerical model of coral bleaching.\n",
    "\n",
    "Observational data for coral bleaching has been collected in various ways, most prominently ReefBase and more recently in a large high-resolution database <a href=\"#refs\">(Donner, Rickbeil, & Heron 2017)</a>.  While those databases are extensive and valuable, their data have been collected from such a diverse array of sources that their accuracy is questionable.  This has been addressed in a more recent effort which covers only 100 selected areas around the world, but does so with a more consistent approach and using more carefully vetted sources <a href=\"#refs\">(Hughes et al. 2018)</a>.  That paper is the source of the observational data I use in this project.\n",
    "\n",
    "Numerical models of coral reef health must make tradeoffs between ecosystem detail, coverage, predictive ability, and run time.  Because each coral region around the world has a different species assemblage, different human impacts, and different ocean conditions, it is impossible to obtain input data on a fine enough scale to model each of the world's reefs in detail.  The approach I consider here is able to model every significant coral reef area in the world.  It does that by simplifying a coral reef to two species of coral and two to four strains of symbiotic algae.  The model numerically integrates a set of differential equations in time to predict coral cover.  Bleaching is deduced from the rate of change in coral cover <a href=\"#refs\">(Logan et al. 2018)</a>.  With these simplifications, the model is not meant to predict outcomes on specific reefs.  It is meant to be used for comparing different climate scenarios and interventions on a global basis, using the individual reefs to represent the range of SST and ocean acidification histories reefs are likely to seen.\n",
    "\n",
    "## NEED LOGAN DETAIL!\n",
    "\n",
    "Within the code and comments of this project I will use abbreviated terms to refer to these two papers and approaches.\n",
    "\n",
    "|Paper:  |<a href=\"#refs\">Logan et al. 2018</a> | <a href=\"#refs\">Hughes et al. 2018</a>|\n",
    "|-------|------------------|-------------------|\n",
    "|Unit of reef area: | Logan cell | Hughes area|\n",
    "|or simply: | cell | area|\n",
    "|count of cells/areas: | 1,925 | 100 |\n",
    "|size ($km^2$): | 4120-10832 | 2-9319|\n",
    "\n",
    "\n",
    "This project compares bleaching events as estimated in Logan cells and counted in Hughes areas.  In Hughes a severe bleaching event is declared when at least 30% of the coral surveyed is bleached.  In Logan bleaching is signaled by a 30% drop in symbiont populations or a 10% drop in coral cover.  These definitions are reasonably compatible, but other aspects of the two datasets are more difficult to deal with.  Hughes areas are unevenly distributed around the world, and their areas are given but not their shapes.  When treating Hughes areas as circles what a radius calculated from the given area, twenty one of the Hughes areas do not overlap a Logan cell, and only 143 (less than 10%) of the Logan cells overlap a Hughes area.\n",
    "\n",
    "Even with complete overlap between cells and areas, a reef-by-reef comparision would not be exact, due to the simplifications and assumptions described earlier.  My goal is only to see how much correlation there is, both reef-by-reef and regionally, between the two datasets.  This will help guide future efforts to calibrate the numerical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"methods\"></a>\n",
    "## Methods\n",
    "This analysis looks at the Hughes et al. and Logan et al. datasets in several ways.  Some proved less productive than others, but they are still included to demonstrate what was tried.\n",
    "\n",
    "The first part of the analysis simply looks at the <a href=\"#mapcompare\">two datasets on maps of the world</a>, as a tool for understanding what is there.  The <a href=\"#matching\">cells and areas are matched</a>, and Logan cells are assigned to regions of the world, chosen based on the approach in Hughes et al. 2018.\n",
    "\n",
    "In order to see if there is a correlation between bleaching event counts in the two datasets, the matched cells and areas are <a href=\"#reefbyreef\">scatterplotted</a> against each other.  The idea is that while exact matches are not expected, there should be an overall correlation between high-bleaching and low-bleaching locations.  The initial global comparison showed little to no correlation, so regional comparisons were tried, but still there was nothing.\n",
    "\n",
    "With the idea that the uncorrelated scatter plots might be hiding correlations which would apply to subsets of the data, I tried a <a href=\"#pca\">principal component analysis</a> looking at key variables SST, SST variance, longitude, and absolute value of latitude.  Longitude was then removed because even though it affected the results there was no biological meaning to the numerical values.  Although this analysis was interesting, with only few variables to consider I wasn't able to further simplifly the problem.\n",
    "\n",
    "Since the PCA analysis was not helpful I tried simply <a href=\"#variable_scatter\">plotting the variables against each other</a>.  This time there were definite trends, but most of them were fairly obvious, such as showing that SST is lower and more variable at higher latitudes.\n",
    "\n",
    "All of the previous analyses which considered bleaching events looked at the total number of events between 1980 and 2016, the years included in Hughes et al. 2018.  One final approach was to look at <a href=\"#cumulative\">cumulative bleaching</a> on a year-by-year basis.  This made it possible to look at trends over time.\n",
    "\n",
    "<a id=\"data\"></a>\n",
    "## Data Sources\n",
    "The research which created input data for this project was described in the introduction.  Specific inputs are\n",
    "1. From Hughes et al. (2018), their supplementary Table S1, a 5-page table with 349 references.  The document is doc/Hughes_et al._2018 Science-Anthropocene bleaching patterns_SM.pdf.  The data used as input has been hand-corrected and placed in data/Hughes100Reefs.xlsx\n",
    "1. For Logan et al. (2018), input file data/ESM2M_SSTR_JD.mat contains the latitude and longitude of the centroid of each Logan cell, as well as a monthly simulated SST history for that cell from 1861 to 2100 (Dunne et al. 2012).\n",
    "1. data/HughesCompEvents_selV_rcp60E=1OA=1.mat is a MATLAB data file with bleaching counts from a custom run of the Logan et al. model, with counts of bleaching events in the Hughes time frame of 1980 to 2016.\n",
    "\n",
    "The Logan data is unpublished, and so should not be used publicly before the release of Logan et al. (2018)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "This project runs in the Jupyter Notebook using the python language.  It has several other code dependencies.\n",
    "\n",
    "### Publicly available libraries\n",
    "- cartopy.crs\n",
    "- cartopy.mpl.ticker\n",
    "- copy\n",
    "- math\n",
    "- matplotlib.pyplot\n",
    "- numpy\n",
    "- pandas\n",
    "- scipy.io\n",
    "- scipy.linalg\n",
    "- scipy.spatial\n",
    "- scipy.stats\n",
    "- sys\n",
    "\n",
    "### My code stored in .py files\n",
    "- Functions in principal_component.py\n",
    "    - pca\n",
    "- Functions in coral_project_functions.py\n",
    "    - make_coral_map\n",
    "    - bleach_scatter\n",
    "    - scatter_all\n",
    "    - bleach_annual_plot\n",
    "    - cumulativesum\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"results\"></a>\n",
    "## Results\n",
    "The bulk of the notebook follows, starting with data input and then showing the code and results for each analysis step.  These are in the same order as listed in the methods section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from coral_project_functions import make_coral_map\n",
    "\n",
    "# Read data from the Hughes supplemental material.  The first\n",
    "# sheet is a cut-and-paste from their document with obvious typos\n",
    "# fixed by hand and a few columns added for easier data manipulation.\n",
    "# The second sheet has been arranged for easier import.\n",
    "filename = '../data/Hughes100Reefs.xlsx' \n",
    "hughes = pd.read_excel(filename,header=0,sheet_name=1, na_values='-')\n",
    "# Missing size values are set to zero - be careful how they are used later!\n",
    "# hughes.Size_km2 = hughes.Size_km2.replace({\"-\": \"0\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"HughesData\"></a>\n",
    "### Columns from Hughes et al. are\n",
    "1. Hughes Reef - the index used in their data, 1-100.\n",
    "2. Region - my code for their region labels.\n",
    "    + AuA - Australasia\n",
    "    + IO-ME - Indian Ocean/ Middle East\n",
    "    + Pac - Pacific\n",
    "    + WAtl - West Atlantic\n",
    "3. Location - their location name for each reef. \n",
    "4. Numeric Lat - decimal values between about -35 and +35\n",
    "5. Numeric Lon - decimal values between -180 and +180\n",
    "6. Size_km2 - area in square kilometers, sometimes omitted.\n",
    "7. Year - columns 7 to 43 - one column for each year of data, 1980 to 2016.  Values are blank, S, or M.\n",
    "44. Severe count - the count of the number of cells in this row with the entry \"S\". values 0-7\n",
    "45. Moderate count - the count of the number of cells in this row with the entry \"M\".  Values 0-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read our data for reef cell locations.\n",
    "import scipy.io as sio\n",
    "\n",
    "# Reference for all data for the 1,925 reef cell model.\n",
    "# This has not been submitted to a journal yet, so all is subject to change:\n",
    "#\n",
    "# Logan, C. A., Dunne, J. P., Ryan, J. S., Baskett, M. L. & Donner, S. D. Can symbiont\n",
    "# diversity and evolution allow corals to keep pace with global warming\n",
    "# and ocean acidification? prep (2018).\n",
    "\n",
    "# A copy of the data is in this repository.  The reference copy is in\n",
    "# my Coral-Model-Data repository in the ProjectionsPaper directory.\n",
    "mat_data = sio.loadmat('../data/ESM2M_SSTR_JD.mat')\n",
    "# Put just the lat/lon columns into a data frame.  Note that they are stored\n",
    "# with longitude first in the incoming data.\n",
    "cells = pd.DataFrame(mat_data['ESM2M_reefs_JD'], columns=['Lon', 'Lat'])\n",
    "\n",
    "# The same mat file has SST data, not used in this notebook until the PCA section.\n",
    "sst = mat_data['SSTR_2M26_JD']\n",
    "cells['SST'] = np.mean(sst, axis=1)\n",
    "cells['variance'] = np.var(sst, axis=1)\n",
    "\n",
    "del sst  # big, and no longer needed (though the value of del is debated online)\n",
    "\n",
    "# Next, read the bleaching counts from a MATLAB mat file written for this purpose.\n",
    "mat_data = sio.loadmat('../data/HughesCompEvents_selV_rcp60E=1OA=1.mat')\n",
    "# Put the bleaching counts into a data frame.  These counts are the total for each\n",
    "# reef during 1980 to 2016.\n",
    "modelBleaching = pd.DataFrame(mat_data['events80_2016'])\n",
    "modelBleaching.rename(columns={0: 'Events'}, inplace=True)\n",
    "# Be we really want this in the cells dataframe\n",
    "cells['Events'] = modelBleaching['Events']\n",
    "\n",
    "# For later use, also load the un-summarized data which has the bleaching\n",
    "# flags for each reef and year from 1980 to 2016.  Branching and massive coral\n",
    "# are treated separately.\n",
    "massive_bleach = np.array(mat_data['events80_2016_detail'][:, :, 0])\n",
    "branching_bleach = np.array(mat_data['events80_2016_detail'][:, :, 1])\n",
    "\n",
    "del mat_data\n",
    "del modelBleaching\n",
    "cells.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoganData\"></a>\n",
    "### Columns from the Logan et al. data are\n",
    "For each cell:\n",
    "1. Lat - the latitude of the centroid\n",
    "2. Lon - the longitude of the centroid\n",
    "3. Events - the number of bleaching events between 1980 and 2016, inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 4])\n",
    "ax = make_coral_map()\n",
    "\n",
    "# Hughes reef areas can be large.  Make size proportional.  Conveniently, the marker\n",
    "# size argument is in square units.  However, our map is in degree units and the areas\n",
    "# are in kilometers.  This is a rough conversion relating pixels to square degrees.\n",
    "conversion = 120*(1/111)**2\n",
    "area_sizes = hughes.Size_km2.astype(float)\n",
    "# Do some stats with no NaN values\n",
    "sss = area_sizes[~np.isnan(area_sizes)]\n",
    "print(\"Area size min/max/mean/median:\", min(sss), max(sss), np.mean(sss), np.median(sss), 'km^2')\n",
    "\n",
    "lon = hughes['Numeric Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), hughes['Numeric Lat'], marker='o',\n",
    "            s=conversion*area_sizes,\n",
    "            label='Hughes Areas', transform=ccrs.PlateCarree())\n",
    "# Mark our cells with small dots.\n",
    "lon = cells['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells['Lat'], marker='.', s=1, label='Cell centers',\n",
    "           transform=ccrs.PlateCarree())\n",
    "plt.title('Reef locations')\n",
    "plt.legend()\n",
    "plt.text(110, 25, 'Caribbean')\n",
    "plt.text(-60, -25, 'Australia')\n",
    "plt.text(-152, 9, 'Red\\nSea')\n",
    "plt.text(20, 25, 'Hawaii')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now try an indication of bleaching severity.\n",
    "plt.figure(figsize=[12, 4])\n",
    "ax = make_coral_map()\n",
    "lon = hughes['Numeric Lon']\n",
    "severity = hughes['Severe count']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), hughes['Numeric Lat'], marker='o', \n",
    "            s=conversion*area_sizes,\n",
    "            label='Hughes Areas',\n",
    "            c=severity,\n",
    "            cmap=\"plasma\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.title('Hughes Severe Bleaching Events, 1980-2016', fontsize=14)\n",
    "plt.clim(0, 10)\n",
    "plt.colorbar(pad=0.02)\n",
    "plt.text(110, 25, 'Caribbean')\n",
    "plt.text(-60, -25, 'Australia')\n",
    "plt.text(-152, 9, 'Red\\nSea')\n",
    "plt.text(20, 25, 'Hawaii');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Look at Bleaching events from the numerical model, using the same scale as\n",
    "# the previous plot of Hughes data.\n",
    "plt.figure(figsize=[12, 4])\n",
    "ax = make_coral_map()\n",
    "\n",
    "lon = cells['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells['Lat'], c = cells['Events'],\n",
    "            marker='.', s=1, label='Events', cmap=\"plasma\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "plt.title('Logan Modeled Bleaching Events, 1980-2016')\n",
    "plt.clim(0, 10)\n",
    "plt.colorbar(pad=0.10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hughes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"matching\"></a>\n",
    "### Matching Hughes areas to Logan reef cells\n",
    "To make a fair comparison, we need to figure out which of our cells match Hughes reef areas.  Each area has a center and an area, so we can use a circle of that area as a first-order guess.  Unfortunately, it seems that the areas are actually far from circular, because some of the centers are far inland.\n",
    "\n",
    "The code below uses a scipy tool to find spatial matches between the two sets of data.  The matches found here can be considered close matches, because the cells must overlap, or nearly so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use scipy.spatial.cKDTree to find neighbors.\n",
    "from scipy import spatial\n",
    "# Build the tree (a binary trie) of our cells.\n",
    "# NOTE: cells.as_matrix({'Lon', 'Lat'}) does not return the columns in a determinate order!\n",
    "# explicitly stack the columns instead.\n",
    "lonlat = np.column_stack((cells['Lon'], cells['Lat']))\n",
    "tree = spatial.cKDTree(lonlat)\n",
    "\n",
    "# For each of the 100 Hughes cells, get a list of our cells which are likely to overlap.\n",
    "# These will be used\n",
    "hughes = hughes.assign(radius_km=hughes.Size_km2**0.5)\n",
    "cell_lists = [[] for i in range(len(hughes))]\n",
    "match_idx = np.zeros(len(hughes), dtype=np.bool)\n",
    "for i in range(len(hughes)):\n",
    "    # convert radius to degrees (ignoring change of size with latitude for now)\n",
    "    # also, add 0.5 degrees as a rough allowance for our cell size\n",
    "    # radius = 0.5 + hughes.radius_km[i] / 111\n",
    "    radius = 0.5 + hughes.radius_km[i] / 111\n",
    "    c = tree.query_ball_point([hughes['Numeric Lon'][i], hughes['Numeric Lat'][i]],\n",
    "                              radius, n_jobs=2)\n",
    "    # Convert zero-based indexes to 1-based cell numbers.\n",
    "    cell_lists[i] = [x+1 for x in c]\n",
    "    match_idx[i] = len(c) > 0\n",
    "\n",
    "print(cell_lists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"mapcompare\"></a>\n",
    "### Comparison of beaching in each area\n",
    "Now that areas and cells are associated, we can store nearby Logan bleaching values in the Hughes dataframe and use that to plot a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now that we have a correspondence between Hughes areas and Logan cells, we can\n",
    "# compare the bleaching for those which have some overlap.\n",
    "# Add a column for cell-based bleaching values\n",
    "hughes = hughes.assign(cell_bleach=np.zeros(len(hughes)))\n",
    "for i in range(len(hughes)):\n",
    "    if len(cell_lists[i]) > 0:\n",
    "        count = 0;\n",
    "        for n in cell_lists[i]:\n",
    "            # \"n-1\" because cells are 1-based and modelBleaching is 0-based\n",
    "            count = count + cells.loc[n-1, 'Events']\n",
    "        hughes.loc[i, 'cell_bleach'] = count / len(cell_lists[i])\n",
    "        \n",
    "# Plot the Hughes reefs, but only those which have Logan cells to compare to.\n",
    "# Color the markers by the difference between the two bleaching values.\n",
    "plt.figure(figsize=[12, 4])\n",
    "ax = make_coral_map()\n",
    "\n",
    "conversion = 120*(1/111)**2\n",
    "lon = hughes[match_idx]['Numeric Lon']\n",
    "\n",
    "print(\"There are\", len(lon), \"areas with comparisons.\")\n",
    "severity = hughes[match_idx]['Severe count'] - hughes[match_idx]['cell_bleach']\n",
    "\n",
    "plt.scatter(lon, hughes[match_idx]['Numeric Lat'], marker='o', \n",
    "            s=conversion*hughes[match_idx].Size_km2.astype(float),\n",
    "            label='Hughes Areas',\n",
    "            c=severity,\n",
    "            cmap='coolwarm',\n",
    "            transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.title('Hughes Bleaching - Cell Bleaching, 1980-2016')\n",
    "plt.clim(-8, 8)\n",
    "plt.colorbar(pad=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning every cell a Hughes region\n",
    "While not every area closely matches a cell and vice versa, it is reasonable to assign all Logan cells to some Hughes area of the world.  This is done by matching each cell to a nearby area, where the definition of \"nearby\" is relaxed until all cells have been matched.\n",
    "\n",
    "There are two things to note here.  First, while most reef cells fall near an area treated by Hughes, Hughes has no areas on the Atlantic coast of Brazil.  Those are assigned to the \"West Atlantic\" region, but they are likely to be ecologically quite different than the Hughes \"West Atlantic\" areas, which are in the Caribbean and Gulf of Mexico, or north toward the Bahamas and Bermuda.  Second, some reef are reassigned manually because their proximity to the isthmus of Panama led to poor results with the automatic method.\n",
    "\n",
    "Also, Hughes has no areas in the Solomon Islands or the Bismarck Sea N.E. of New Guinea.  It is not clear whether they are a better match to the Pacific or Australasian regions.  I have left these as matched automatically, except for a small group which are clearly Micronesian, in the Pacific region and one cell which may be Nauru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column\n",
    "cells = cells.assign(Region='none')\n",
    "cells_assigned = 0\n",
    "r = 0.5\n",
    "while cells_assigned < 1925:\n",
    "    for i in range(len(hughes)):\n",
    "        # 0 gives 15 comparisons, 0.5 gives 76, 2.0 gives 93.  In all cases there's an\n",
    "        # insignificant negative correlation in bleaching.\n",
    "        radius = r + hughes.radius_km[i] / 111\n",
    "        c = tree.query_ball_point([hughes['Numeric Lon'][i], hughes['Numeric Lat'][i]],\n",
    "                                  radius, n_jobs=-1)\n",
    "        region = hughes.Region[i]\n",
    "        #print('Reef', i, 'region', region, 'found ', c)\n",
    "        for x in c:\n",
    "            if cells.loc[x, 'Region'] == 'none':\n",
    "                cells.loc[x, 'Region'] = region\n",
    "                cells_assigned = cells_assigned + 1\n",
    "    print('After r =', r, ',', cells_assigned, 'are assigned.')\n",
    "    r = r * 2\n",
    "\n",
    "# Some special cases are mis-identified with the approach above.\n",
    "# South atlantic, off Brazil is initially id'd as Indian Ocean/ Middle East!\n",
    "# Make a bounding box to specify these cells\n",
    "box = [-40, -25, -26, -16]  # Lon, Lon, Lat, Lat \n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"WAtl\"\n",
    "# Others off Brazil are labeled Pacific.\n",
    "box = [-39, -34, -16, -8]\n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"WAtl\"\n",
    "# Some SW Caribbean cells are id'd as Pacific\n",
    "#11.6, -83.7\n",
    "#box = [-83, -80,  12, 16]\n",
    "box = [-83.8, -80,  11.5, 16]\n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"WAtl\"\n",
    "box = [-81, -76, 8.8, 11]\n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"WAtl\"\n",
    "# A few micronesian cells are closer to a Hughes area sound of New Guinea than to micronesian\n",
    "# areas, but they clearly belong with micronesia\n",
    "box = [147, 153, 4, 11]\n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"Pac\"\n",
    "# Nauru?\n",
    "box = [164, 169, -1, 3]\n",
    "cells.loc[(cells.Lat > box[2]) & (cells.Lat < box[3]) & (cells.Lon > box[0]) &\n",
    "          (cells.Lon < box[1]), 'Region'] = \"Pac\"\n",
    "\n",
    "print('Pacific:', sum(cells['Region'] == 'Pac'))\n",
    "print('Indian Ocean - Middle East:', sum(cells['Region'] == 'IO-ME'))\n",
    "print('Australasia:', sum(cells['Region'] == 'AuA'))\n",
    "print('West Atlantic:', sum(cells['Region'] == 'WAtl'))\n",
    "print()\n",
    "\n",
    "# Save the cells with region labels for use in another notebook.  This is\n",
    "# only used in Reef_PCA_Scatterplots.\n",
    "cells.to_pickle('../results/Logan_cells_events_region.pkl')\n",
    "cells.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Logan cells colored by region to check the assignments.\n",
    "# First give each region number for easy use of a color map.\n",
    "cells = cells.assign(RegionFlag='0')\n",
    "cells.loc[cells.Region=='Pac', 'RegionFlag'] = 1;\n",
    "cells.loc[cells.Region=='AuA', 'RegionFlag'] = 2;\n",
    "cells.loc[cells.Region=='IO-ME', 'RegionFlag'] = 3;\n",
    "cells.loc[cells.Region=='WAtl', 'RegionFlag'] = 4;\n",
    "\n",
    "plt.figure(figsize=[12, 4])\n",
    "ax = make_coral_map()\n",
    "lon = cells[cells.RegionFlag==1]['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells[cells.RegionFlag==1]['Lat'], c = [1.0, 0, 0],\n",
    "            marker='.', s=2, label='Pacific', cmap=\"Dark2\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "lon = cells[cells.RegionFlag==2]['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells[cells.RegionFlag==2]['Lat'], c = [0, 1.0, 0],\n",
    "            marker='.', s=1, label='Australasia', cmap=\"Dark2\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "lon = cells[cells.RegionFlag==3]['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells[cells.RegionFlag==3]['Lat'], c = [0, 0, 1.0],\n",
    "            marker='.', s=1, label='Indian Ocean - Middle East', cmap=\"Dark2\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "lon = cells[cells.RegionFlag==4]['Lon']\n",
    "plt.scatter(lon-180*(np.sign(lon)-1), cells[cells.RegionFlag==4]['Lat'], c = [0, 0, 0],\n",
    "            marker='.', s=1, label='West Atlantic', cmap=\"Dark2\",\n",
    "            transform=ccrs.PlateCarree())\n",
    "plt.title('Logan Cells Colored by Hughes Region')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reefbyreef\"></a>\n",
    "### Reef-by-reef bleaching correlation\n",
    "The initial comparison between Hughes areas and Logan reefs doesn't look great.  Try a scatterplot for all of the Hughes areas to see if there's at least some trend.  This is first done for the world, and then for each region separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from coral_project_functions import bleach_scatter\n",
    "\n",
    "h_match = hughes[match_idx]   \n",
    "plt.figure()\n",
    "bleach_scatter(hughes[match_idx], 'World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now see if the correlation is better regionally.\n",
    "plt.figure(figsize=[9, 6])\n",
    "plt.subplot(2,2,1)\n",
    "h_match_region = h_match[h_match['Region'] == 'Pac']\n",
    "bleach_scatter(h_match_region, 'Pacific')\n",
    "plt.subplot(2,2,2)\n",
    "h_match_region = h_match[h_match['Region'] == 'WAtl']\n",
    "bleach_scatter(h_match_region, 'Atlantic')\n",
    "plt.subplot(2,2,3)\n",
    "h_match_region = h_match[h_match['Region'] == 'AuA']\n",
    "bleach_scatter(h_match_region, 'Australasia')\n",
    "plt.subplot(2,2,4)\n",
    "h_match_region = h_match[h_match['Region'] == 'IO-ME']\n",
    "bleach_scatter(h_match_region, 'Indian Ocean - Middle East')\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier notes\n",
    "The two Pacific outlying locations are in the Galapagos and Kiribati, to use their Hughes names.  \n",
    "The Galapagos has a land area of around 7000 $km^2$ and Hughes has a reef area of 126 $km^2$.\n",
    "Kiribati has a land area of 800 $km^2$ (wikipedia) and Hughes has a reef area of 1718 $km^2$.\n",
    "While Kiribati is closer to the Galapagos than most Pacific islands and they are both\n",
    "equatorial, they are quite far apart (over 90 deg longitude) and there is little reason\n",
    "to group them.\n",
    "\n",
    "The three Atlantic outlying locations are Bonaire, Curacao, and Venezuela, to use their Hughes names.  \n",
    "Curacao has a land area of 444 $km^2$ (Wikipedia) and Hughes has a reef area of 47 $km^2$.\n",
    "Bonaire has a land area of 295 $km^2$ (wikipedia) and Hughes has a reef area of 22 $km^2$.\n",
    "Venezuela is continental, and the Hughes are is 349 $km^2$, perhaps corresponding to the Gran Roque reef east of Bonaire.\n",
    "It is interesting that these outliers are adjacent, and have low bleaching according to Hughes and higher bleaching in our model.\n",
    "Repeating the plot with these three locations removed only decreases the $R^2$ value, and the slope is still negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another subset approach - by size\n",
    "Plot this same comparison using only the smallest and only the largest reef areas, based on Hughes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_area = np.median(h_match['Size_km2'])\n",
    "h_match_big = h_match[h_match['Size_km2'] >= median_area]\n",
    "h_match_small = h_match[h_match['Size_km2'] < median_area]\n",
    "\n",
    "plt.figure(figsize=[9, 4])\n",
    "# Biggest half\n",
    "plt.subplot(1,2,1)\n",
    "bleach_scatter(h_match_big, 'Large areas')\n",
    "\n",
    "# Smallest half\n",
    "plt.subplot(1,2,2)\n",
    "bleach_scatter(h_match_small, 'Small areas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pca\"></a>\n",
    "### Principal Components Analysis\n",
    "Given that the scatter plots don't show relationships at the global or regional level, perhaps PCA can reveal some grouping by temperature, temperature variability, or longitude which will turn up something interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a numerical value, the absolute value of latitude is more likely to be useful than the\n",
    "# signed value.\n",
    "cells['abs_lat'] = abs(cells['Lat'])\n",
    "\n",
    "all_names = list(cells)\n",
    "all_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# function moved so this project is self-contained:\n",
    "import principal_component as pc\n",
    "\n",
    "# Longitude does have a relationship with bleaching, but it's more categorical\n",
    "# than scalar, so omit it.  Also omit signed Latitude.  Also remove Region, because it is\n",
    "# categorical and we hope to find a better grouping.\n",
    "print('PCA including only unsigned latitude:')\n",
    "print('all names:', all_names)\n",
    "# Without deepcopy, removing names from the list affects the original.\n",
    "reduced_names = copy.deepcopy(all_names)\n",
    "reduced_names.remove('Lat')\n",
    "reduced_names.remove('Lon')\n",
    "reduced_names.remove('Region')\n",
    "reduced_names.remove('RegionFlag')\n",
    "reduced_names.remove('Events')\n",
    "\n",
    "[eigenval, eigenvec, pct_acct, loadings, sorted_names] = pc.pca(np.asmatrix(cells[reduced_names]),\n",
    "     reduced_names, standardize=True, sort=True)\n",
    "print('Names:    ', sorted_names)\n",
    "print('Eigenvalues:\\n', eigenval)\n",
    "print('Eigenvectors:\\n', eigenvec)\n",
    "print('Variance accounted for by each component:\\n', pct_acct)\n",
    "#print('Component loadings:\\n', loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at factor loadings for the reduced list\n",
    "# A = V (sqrt(Lambda))\n",
    "# V = eigenvectors = eigenvec\n",
    "# Lambda = eigenvalue matrix = eigenval\n",
    "A = np.matmul(eigenvec, np.diag(eigenval)**0.5)\n",
    "# A now contains the loadings for PC1 in the first row, and so on.\n",
    "A\n",
    "plt.figure()\n",
    "plt.plot(A[:, 0], A[:, 1], 'o')\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.xlabel('PC1 loading')\n",
    "plt.ylabel('PC2 loading')\n",
    "for i, txt in enumerate(sorted_names):\n",
    "    plt.text(A[i,0]+0.05,A[i,1],txt)\n",
    "sorted_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elimination of PCA\n",
    "Since there are so few variables, PCA was not likely to be useful here, but I have included it because it was interesting as a way of thinking through the possible contribution of each  variable.  The plot about does not seem to reveal anything useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"variable_scatter\"></a>\n",
    "### Looking at scatter plots for Hughes/Logan correlation\n",
    "Since Principal Components Analysis did not seem helpful here, I tried simply plotting each variable against the others.  Plots for all reefs are shown below, and versions for each region separately are in another notebook.  [Reef_PCA_Scatterplots](Reef_PCA_Scatterplots.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from coral_project_functions import scatter_all\n",
    "plt.figure(figsize=[8, 6])\n",
    "scatter_all(cells[['Events', 'abs_lat', 'SST', 'variance']])   \n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cumulative\"></a>\n",
    "### Cumulative Bleaching approach\n",
    "Perhaps reefs will simply not correlate on an individual basis, but the cumulative bleaching in an area is of interest.  Go back to using the hughes and cells arrays without regard to individual matches.  The plot below is scaled to show the same number of total events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from coral_project_functions import bleach_annual_plot\n",
    "\n",
    "# The annual bleaching count for the whole world, based on Logan et al. (2018) and Hughes et al. (2018)\n",
    "# Values are normalized since the two datasets cover different areas.\n",
    "plt.figure(figsize=[9, 6])\n",
    "bleach_annual_plot(branching_bleach, massive_bleach, hughes, 'Annual Bleaching, Global')\n",
    "\n",
    "#shiftYear = -1.5\n",
    "#plt.plot(range(1980, 2017), hughes_norm, label='Hughes')\n",
    "#plt.plot(shiftYear+np.array(range(1980, 2017)), cell_norm, label='Logan')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now do the same thing for each region separately.\n",
    "plt.figure(figsize=[9, 6])\n",
    "plt.suptitle(\"Cumulative Bleaching Events\", fontsize=14)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "c_idx = cells['Region'] == 'AuA'\n",
    "h_idx = hughes['Region'] == 'AuA'\n",
    "bleach_annual_plot(branching_bleach[c_idx], massive_bleach[c_idx], hughes[h_idx], 'Australasia', True)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "c_idx = cells['Region'] == 'Pac'\n",
    "h_idx = hughes['Region'] == 'Pac'\n",
    "bleach_annual_plot(branching_bleach[c_idx], massive_bleach[c_idx], hughes[h_idx], 'Pacific', True)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "c_idx = cells['Region'] == 'IO-ME'\n",
    "h_idx = hughes['Region'] == 'IO-ME'\n",
    "bleach_annual_plot(branching_bleach[c_idx], massive_bleach[c_idx], hughes[h_idx], 'Indian Ocean - Middle East', True)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "c_idx = cells['Region'] == 'WAtl'\n",
    "h_idx = hughes['Region'] == 'WAtl'\n",
    "bleach_annual_plot(branching_bleach[c_idx], massive_bleach[c_idx], hughes[h_idx], 'Western Atlantic - Caribbean', True)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of cumulative bleaching\n",
    "1. The curves have been scaled to reach the same endpoint.  Only the rate of increase over time is of interest.\n",
    "2. The model SST data matches the typical frequency of events such as El Nino, but not the exact timing, so the exact dates of jumps is not comparable.\n",
    "3. This really should be repeated with actual historical temperatures, but I only fully appreciated that on May 7.  It is unlikely that I can obtain and scale appropriate data before the due date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "This project did not show the correlations which were expected.  While perfect correlation between bleaching rates in the observational and modeled data were not expected, I did expect to see something.  In fact, there was no discernable match at the reef level.\n",
    "\n",
    "The does seem to match the variability in bleaching, as can be seen in the Annual Bleaching figure, and there is some similarity of shape in the cumulative plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "There is one immediate next step which should be done.  Because the SST history (Dunne et al. 2012) is model-based it simulates the frequency and magnitude of SST variations but not their actual timing.  Because of this, there can be no expectation of bleaching events occuring in specific years, even if overall trends are correct.  There are historical datasets available which use actual temperatures where possible, with missing locations and dates filled in using statistical methods.  The model should be re-run with one of these.  Then it should be possible to repeat the cumulative bleaching comparison and expect peak years to coincide if the model is correct.\n",
    "\n",
    "To improve the usefulness of comparisons with the Hughes data, one useful step would be to obtain more complete definitions of the larger areas used in the paper.  Careful examination of the size and centroid locations of areas including the Great Barrier Reef shows that some of the areas must be quite elongated.  A shapefile or even a rough outline of each area would enable a better match between Hughes areas and Logan cells.  It would also be nice if Hughes, though currently limited to 100 areas, could add fill in just a few under-covered areas.  Two examples are the Atlantic coast of Brazil, where there is no coverage at all, and Micronesia, for example the Chuuk Lagoon area, where there is a high density of reefs with no close Hughes area.\n",
    "\n",
    "Finally, it is important to remember that the Logan model is not meant to produce predictions for individual reefs.  Although this project has attempted to look for reef-level correlations, the Logan et al. data should always be presented with the footnote that there is not enough detail to capture reef-level variations.  This should not take away from the fact that the Logan model is useful for examining large-scale trends and differences between climate, evolution, or other scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='refs'></a>\n",
    "## References\n",
    "\n",
    "Donner, S. D., Rickbeil, G. J. M. & Heron, S. F. A new, high-resolution global mass coral bleaching database. PLoS One 12, e0175490 (2017).\n",
    "\n",
    "Dunne, J. P., John, J. G., Adcroft, A. J., Griffies, S. M., Hallberg, R. W., Shevliakova, E., ... & Krasting, J. P. (2012). GFDL's ESM2 global coupled climate-carbon Earth System Models. Part I: Physical formulation and baseline simulation characteristics. Journal of Climate, 25(19), 6646-6665.\n",
    "\n",
    "Frieler, K. et al. Limiting global warming to 2 °C is unlikely to save most coral reefs. Nat. Clim. Change 3, 165–170 (2013).\n",
    "\n",
    "Hughes, T. P. et al. Spatial and temporal patterns of mass bleaching of corals in the Anthropocene. Science 359, 80–83 (2018).\n",
    "\n",
    "Logan, C. A., Dunne, J. P., Ryan, J. S., Baskett, M. L. & Donner, S. D. Can symbiont diversity and evolution allow corals to keep pace with global warming and ocean acidification? prep (2018).\n",
    "\n",
    "Logan, Cheryl A., John P. Dunne, C. Mark Eakin, and Simon D. Donner. 2014. “Incorporating Adaptive Responses into Future Projections of Coral Bleaching.” Global Change Biology 20 (1):125–39. https://doi.org/10.1111/gcb.12390.\n",
    "\n",
    "<a href='#intro'>back to Introduction</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
